import logging

from telegram import Update
from telegram.ext import CallbackContext

from config import ALLOWED_USER_IDS
from services.gemini_service import analyze_content
from services.notion_service.utils import extract_hashtags, remove_hashtags_from_text, merge_tags
from utils.helpers import is_url_only
from utils.text_formatter import (
    extract_urls_from_entities,
    parse_message_entities,
)

from .pdf_handlers import handle_pdf_document
from .test_handlers import handle_test_message
from .todo_handlers import handle_todo_message

# å¯¼å…¥å¤„ç†å™¨
from .url_handlers import handle_multiple_urls_message, handle_url_message

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


def process_message(update: Update, context: CallbackContext) -> None:
    """å¤„ç†æ”¶åˆ°çš„æ¶ˆæ¯"""
    if update.effective_user.id not in ALLOWED_USER_IDS:
        return

    message = update.message
    text = None
    entities = None
    contains_photo = message.photo and len(message.photo) > 0

    # è·å–æ–‡æœ¬å†…å®¹å’Œå®ä½“ï¼ŒåŒºåˆ†æ™®é€šæ–‡æœ¬å’Œå¸¦æ ‡é¢˜çš„åª’ä½“æ¶ˆæ¯
    if message.text:
        text = message.text
        entities = message.entities
    elif message.caption:
        text = message.caption
        entities = message.caption_entities
    else:
        text = ""
        entities = []

    # å¤„ç†æ¶ˆæ¯å®ä½“ï¼Œæå–æ ¼å¼åŒ–ä¿¡æ¯
    parsed_content = parse_message_entities(text, entities)

    # ä»åŸå§‹æ–‡æœ¬ä¸­æå– hashtag æ ‡ç­¾
    original_hashtags = extract_hashtags(parsed_content["text"])
    
    # ä»æ–‡æœ¬ä¸­ç§»é™¤ hashtag æ ‡ç­¾ï¼Œå¾—åˆ°ç”¨äºåˆ†æçš„æ¸…æ´æ–‡æœ¬
    cleaned_text = remove_hashtags_from_text(parsed_content["text"])
    
    # å¦‚æœç§»é™¤æ ‡ç­¾åæ–‡æœ¬ä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œä¿ç•™åŸæ–‡æœ¬è¿›è¡Œå¤„ç†
    if not cleaned_text.strip() or len(cleaned_text.strip()) < 10:
        content_for_analysis = parsed_content["text"]
        content_for_storage = parsed_content["text"]
    else:
        content_for_analysis = cleaned_text
        content_for_storage = parsed_content["text"]  # ä¿å­˜æ—¶ä½¿ç”¨åŸå§‹æ–‡æœ¬ï¼ˆåŒ…å«æ ‡ç­¾ï¼‰

    # è·å–åˆ›å»ºæ—¶é—´
    created_at = message.date

    # å¦‚æœæ¶ˆæ¯åŒ…å«å›¾ç‰‡ï¼Œæ·»åŠ å‰ç¼€
    if contains_photo:
        logger.info(
            f"æ¥æ”¶åˆ°åŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯ï¼Œç”¨æˆ· ID: {update.effective_user.id}ï¼Œå°†åªå¤„ç†æ–‡å­—éƒ¨åˆ†"
        )

        # å¦‚æœå›¾ç‰‡æ¶ˆæ¯æ²¡æœ‰æ–‡å­—è¯´æ˜
        if not text:
            update.message.reply_text(
                "âš ï¸ æ”¶åˆ°å›¾ç‰‡ä½†æ²¡æœ‰æ–‡å­—è¯´æ˜ã€‚è¯·æ·»åŠ è¯´æ˜åé‡æ–°å‘é€ï¼Œæˆ–è€…å•ç‹¬å‘é€è¦ä¿å­˜çš„æ–‡å­—å†…å®¹ã€‚",
                parse_mode=None,  # ç¦ç”¨ Markdown è§£æ
            )
            return

        # ç»™åŸå§‹å†…å®¹æ·»åŠ å‰ç¼€ï¼Œè¡¨æ˜å®ƒæ¥è‡ªåŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯
        content_for_storage = f"[æ­¤å†…å®¹æ¥è‡ªåŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯] {content_for_storage}"
        logger.info(f"å¤„ç†å›¾ç‰‡æ¶ˆæ¯çš„æ–‡å­—å†…å®¹ï¼Œé•¿åº¦ï¼š{len(content_for_storage)} å­—ç¬¦")

    # æå–æ‰€æœ‰ URLï¼ˆä»å®ä½“å’Œæ–‡æœ¬ï¼‰
    urls = extract_urls_from_entities(text, entities)

    # æ£€æŸ¥ç‰¹æ®Šæ ‡ç­¾ï¼ˆä»åŸå§‹æ ‡ç­¾ä¸­æ£€æŸ¥ï¼‰
    if "test" in original_hashtags:
        handle_test_message(update, parsed_content)
        return

    if "todo" in original_hashtags:
        handle_todo_message(update, content_for_storage, created_at)
        return

    # æ£€æŸ¥æ˜¯å¦æ˜¯çº¯ URL æ¶ˆæ¯ï¼ˆä½¿ç”¨æ¸…æ´æ–‡æœ¬æ£€æŸ¥ï¼‰
    if urls and is_url_only(cleaned_text if cleaned_text.strip() else content_for_storage):
        handle_url_message(update, urls[0], created_at)
        return

    # å¤š URL å¤„ç†
    if len(urls) > 1:
        handle_multiple_urls_message(update, content_for_storage, urls, created_at)
        return
    elif len(urls) == 1:
        url = urls[0]
    else:
        url = ""

    # çŸ­å†…å®¹å¤„ç†ï¼šå¦‚æœå†…å®¹ä¸æ˜¯çº¯ URL ä¸”å°‘äº 200 å­—ç¬¦ï¼Œç›´æ¥å°†å†…å®¹ä½œä¸ºæ‘˜è¦
    if len(content_for_analysis) < 200:
        # é€šçŸ¥ç”¨æˆ·æ­£åœ¨å¤„ç†æ¶ˆæ¯
        processing_msg = (
            "æ­£åœ¨å¤„ç†æ¶ˆæ¯..." if not contains_photo else "æ­£åœ¨å¤„ç†å›¾ç‰‡æ¶ˆæ¯çš„æ–‡å­—å†…å®¹..."
        )
        update.message.reply_text(processing_msg, parse_mode=None)  # ç¦ç”¨ Markdown è§£æ

        # ä»éœ€ä½¿ç”¨ Gemini API åˆ†ææå–æ ‡ç­¾
        analysis_result = analyze_content(content_for_analysis)
        
        # åˆå¹¶åŸå§‹æ ‡ç­¾å’Œ AI æ ‡ç­¾
        merged_tags = merge_tags(original_hashtags, analysis_result["tags"])
        
        # å­˜å…¥ Notionï¼Œä½†ä½¿ç”¨åŸå§‹å†…å®¹ä½œä¸ºæ‘˜è¦
        try:
            from services.notion_service import add_to_notion

            # æ³¨æ„ï¼šæ­¤å¤„ä¼ é€’çš„ content åªåŒ…å«æ–‡æœ¬ï¼Œä¸åŒ…å«ä»»ä½•å›¾ç‰‡æ•°æ®
            result = add_to_notion(
                content=content_for_storage,  # ä¿å­˜åŒ…å«æ ‡ç­¾çš„åŸå§‹å†…å®¹
                summary=cleaned_text if cleaned_text.strip() else content_for_storage,  # æ‘˜è¦ä½¿ç”¨æ¸…æ´æ–‡æœ¬
                tags=merged_tags,  # ä½¿ç”¨åˆå¹¶åçš„æ ‡ç­¾
                url=url,
                created_at=created_at,
            )

            update.message.reply_text(
                f"âœ… å·²ä¿å­˜åˆ° Notion\n"
                f"ğŸ“„ {result['title']}\n"
                f"ğŸ”— {result['url']}",
                parse_mode=None
            )
        except Exception as e:
            logger.error(f"æ·»åŠ åˆ° Notion æ—¶å‡ºé”™ï¼š{e}")
            update.message.reply_text(
                f"âš ï¸ ä¿å­˜åˆ° Notion æ—¶å‡ºé”™ï¼š{str(e)}",
                parse_mode=None,  # ç¦ç”¨ Markdown è§£æ
            )
        return

    # é•¿å†…å®¹å¤„ç†ï¼šé€šçŸ¥ç”¨æˆ·æ­£åœ¨å¤„ç†
    processing_msg = (
        "æ­£åœ¨å¤„ç†è¾ƒé•¿æ¶ˆæ¯ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´..."
        if not contains_photo
        else "æ­£åœ¨å¤„ç†å›¾ç‰‡æ¶ˆæ¯ä¸­çš„è¾ƒé•¿æ–‡å­—å†…å®¹ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´..."
    )
    update.message.reply_text(processing_msg, parse_mode=None)  # ç¦ç”¨ Markdown è§£æ

    # ä½¿ç”¨ Gemini API å®Œæ•´åˆ†æå†…å®¹ï¼ˆä½¿ç”¨æ¸…æ´æ–‡æœ¬ï¼‰
    analysis_result = analyze_content(content_for_analysis)
    
    # åˆå¹¶åŸå§‹æ ‡ç­¾å’Œ AI æ ‡ç­¾
    merged_tags = merge_tags(original_hashtags, analysis_result["tags"])

    # å­˜å…¥ Notion
    try:
        from services.notion_service import add_to_notion

        result = add_to_notion(
            content=content_for_storage,  # ä¿å­˜åŒ…å«æ ‡ç­¾çš„åŸå§‹å†…å®¹
            summary=analysis_result["summary"],
            tags=merged_tags,  # ä½¿ç”¨åˆå¹¶åçš„æ ‡ç­¾
            url=url,
            created_at=created_at,
        )

        update.message.reply_text(
            f"âœ… å·²ä¿å­˜åˆ° Notion\n"
            f"ğŸ“„ {result['title']}\n"
            f"ğŸ”— {result['url']}",
            parse_mode=None
        )
    except Exception as e:
        logger.error(f"æ·»åŠ åˆ° Notion æ—¶å‡ºé”™ï¼š{e}")
        update.message.reply_text(
            f"âš ï¸ ä¿å­˜åˆ° Notion æ—¶å‡ºé”™ï¼š{str(e)}",
            parse_mode=None,  # ç¦ç”¨ Markdown è§£æ
        )


def process_document(update: Update, context: CallbackContext) -> None:
    """å¤„ç†æ–‡æ¡£æ–‡ä»¶ï¼Œç‰¹åˆ«æ˜¯ PDF"""
    if update.effective_user.id not in ALLOWED_USER_IDS:
        return

    message = update.message

    # æ£€æŸ¥æ˜¯å¦æ˜¯ PDF æ–‡ä»¶
    if message.document.file_name.lower().endswith(".pdf"):
        handle_pdf_document(update, context)
    else:
        # å¯¹äºé PDF æ–‡ä»¶ï¼Œä½¿ç”¨å¸¸è§„å¤„ç†
        process_message(update, context)
