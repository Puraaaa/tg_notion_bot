import logging
import os
import tempfile

from telegram import Update
from telegram.ext import CallbackContext

from config import ALLOWED_USER_IDS
from services.gemini_service import analyze_content
from services.notion_service.utils import extract_hashtags, remove_hashtags_from_text, merge_tags
from services.notion_service import upload_image_to_notion
from utils.helpers import is_url_only
from utils.text_formatter import (
    extract_urls_from_entities,
    parse_message_entities,
)

from .pdf_handlers import handle_pdf_document
from .test_handlers import handle_test_message
from .todo_handlers import handle_todo_message

# å¯¼å…¥å¤„ç†å™¨
from .url_handlers import handle_multiple_urls_message, handle_url_message

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


def download_and_upload_photos(message, context) -> list:
    """
    ä¸‹è½½ Telegram æ¶ˆæ¯ä¸­çš„å›¾ç‰‡å¹¶ä¸Šä¼ åˆ° Notion

    å‚æ•°ï¼š
        message: Telegram æ¶ˆæ¯å¯¹è±¡
        context: Telegram ä¸Šä¸‹æ–‡å¯¹è±¡

    è¿”å›ï¼š
        list: æˆåŠŸä¸Šä¼ çš„ file_upload_id åˆ—è¡¨
    """
    file_upload_ids = []

    if not message.photo:
        return file_upload_ids

    # Telegram è¿”å›å¤šä¸ªåˆ†è¾¨ç‡çš„å›¾ç‰‡ï¼Œæœ€åä¸€ä¸ªæ˜¯æœ€é«˜åˆ†è¾¨ç‡
    photo = message.photo[-1]

    try:
        # ä¸‹è½½å›¾ç‰‡
        file = context.bot.get_file(photo.file_id)
        temp_path = os.path.join(tempfile.gettempdir(), f"{photo.file_unique_id}.jpg")
        file.download(temp_path)

        try:
            # ä¸Šä¼ å›¾ç‰‡åˆ° Notion
            logger.info(f"å¼€å§‹ä¸Šä¼ å›¾ç‰‡åˆ° Notion: {temp_path}")
            file_upload_id = upload_image_to_notion(file_path=temp_path)

            if file_upload_id:
                file_upload_ids.append(file_upload_id)
                logger.info(f"å›¾ç‰‡ä¸Šä¼ æˆåŠŸï¼Œfile_upload_id: {file_upload_id}")
            else:
                logger.error("å›¾ç‰‡ä¸Šä¼ åˆ° Notion å¤±è´¥")

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(temp_path)
            except OSError as file_error:
                logger.warning(f"æ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼š{file_error}")

    except Exception as e:
        logger.error(f"ä¸‹è½½æˆ–ä¸Šä¼ å›¾ç‰‡æ—¶å‡ºé”™ï¼š{e}")

    return file_upload_ids


def process_message(update: Update, context: CallbackContext) -> None:
    """å¤„ç†æ”¶åˆ°çš„æ¶ˆæ¯"""
    if update.effective_user.id not in ALLOWED_USER_IDS:
        return

    message = update.message
    text = None
    entities = None
    contains_photo = message.photo and len(message.photo) > 0

    # è·å–æ–‡æœ¬å†…å®¹å’Œå®ä½“ï¼ŒåŒºåˆ†æ™®é€šæ–‡æœ¬å’Œå¸¦æ ‡é¢˜çš„åª’ä½“æ¶ˆæ¯
    if message.text:
        text = message.text
        entities = message.entities
    elif message.caption:
        text = message.caption
        entities = message.caption_entities
    else:
        text = ""
        entities = []

    # å¤„ç†æ¶ˆæ¯å®ä½“ï¼Œæå–æ ¼å¼åŒ–ä¿¡æ¯
    parsed_content = parse_message_entities(text, entities)

    # ä»åŸå§‹æ–‡æœ¬ä¸­æå– hashtag æ ‡ç­¾
    original_hashtags = extract_hashtags(parsed_content["text"])
    
    # ä»æ–‡æœ¬ä¸­ç§»é™¤ hashtag æ ‡ç­¾ï¼Œå¾—åˆ°ç”¨äºåˆ†æçš„æ¸…æ´æ–‡æœ¬
    cleaned_text = remove_hashtags_from_text(parsed_content["text"])
    
    # å¦‚æœç§»é™¤æ ‡ç­¾åæ–‡æœ¬ä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œä¿ç•™åŸæ–‡æœ¬è¿›è¡Œå¤„ç†
    if not cleaned_text.strip() or len(cleaned_text.strip()) < 10:
        content_for_analysis = parsed_content["text"]
        content_for_storage = parsed_content["text"]
    else:
        content_for_analysis = cleaned_text
        content_for_storage = parsed_content["text"]  # ä¿å­˜æ—¶ä½¿ç”¨åŸå§‹æ–‡æœ¬ï¼ˆåŒ…å«æ ‡ç­¾ï¼‰

    # è·å–åˆ›å»ºæ—¶é—´
    created_at = message.date

    # å¦‚æœæ¶ˆæ¯åŒ…å«å›¾ç‰‡ï¼Œæ·»åŠ å‰ç¼€
    if contains_photo:
        logger.info(
            f"æ¥æ”¶åˆ°åŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯ï¼Œç”¨æˆ· ID: {update.effective_user.id}ï¼Œå°†å¤„ç†å›¾ç‰‡å’Œæ–‡å­—"
        )

        # å¦‚æœå›¾ç‰‡æ¶ˆæ¯æ²¡æœ‰æ–‡å­—è¯´æ˜ï¼Œä½¿ç”¨é»˜è®¤è¯´æ˜
        if not text:
            text = "å›¾ç‰‡æ¶ˆæ¯"
            content_for_storage = "å›¾ç‰‡æ¶ˆæ¯"
            content_for_analysis = "ç”¨æˆ·åˆ†äº«çš„å›¾ç‰‡"
        else:
            # ç»™åŸå§‹å†…å®¹æ·»åŠ å‰ç¼€ï¼Œè¡¨æ˜å®ƒæ¥è‡ªåŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯
            content_for_storage = f"[æ­¤å†…å®¹æ¥è‡ªåŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯] {content_for_storage}"

        logger.info(f"å¤„ç†å›¾ç‰‡æ¶ˆæ¯çš„æ–‡å­—å†…å®¹ï¼Œé•¿åº¦ï¼š{len(content_for_storage)} å­—ç¬¦")

    # æå–æ‰€æœ‰ URLï¼ˆä»å®ä½“å’Œæ–‡æœ¬ï¼‰
    urls = extract_urls_from_entities(text, entities)

    # æ£€æŸ¥ç‰¹æ®Šæ ‡ç­¾ï¼ˆä»åŸå§‹æ ‡ç­¾ä¸­æ£€æŸ¥ï¼‰
    if "test" in original_hashtags:
        handle_test_message(update, parsed_content)
        return

    if "todo" in original_hashtags:
        handle_todo_message(update, content_for_storage, created_at)
        return

    # æ£€æŸ¥æ˜¯å¦æ˜¯çº¯ URL æ¶ˆæ¯ï¼ˆä½¿ç”¨æ¸…æ´æ–‡æœ¬æ£€æŸ¥ï¼‰
    if urls and is_url_only(cleaned_text if cleaned_text.strip() else content_for_storage):
        handle_url_message(update, urls[0], created_at)
        return

    # å¤š URL å¤„ç†
    if len(urls) > 1:
        handle_multiple_urls_message(update, content_for_storage, urls, created_at)
        return
    elif len(urls) == 1:
        url = urls[0]
    else:
        url = ""

    # çŸ­å†…å®¹å¤„ç†ï¼šå¦‚æœå†…å®¹ä¸æ˜¯çº¯ URL ä¸”å°‘äº 200 å­—ç¬¦ï¼Œç›´æ¥å°†å†…å®¹ä½œä¸ºæ‘˜è¦
    if len(content_for_analysis) < 200:
        # é€šçŸ¥ç”¨æˆ·æ­£åœ¨å¤„ç†æ¶ˆæ¯
        processing_msg = (
            "æ­£åœ¨å¤„ç†æ¶ˆæ¯..." if not contains_photo else "æ­£åœ¨å¤„ç†å›¾ç‰‡æ¶ˆæ¯..."
        )
        update.message.reply_text(processing_msg, parse_mode=None)  # ç¦ç”¨ Markdown è§£æ

        # å¦‚æœæœ‰å›¾ç‰‡ï¼Œå…ˆä¸Šä¼ å›¾ç‰‡
        file_upload_ids = []
        if contains_photo:
            file_upload_ids = download_and_upload_photos(message, context)

        # ä»éœ€ä½¿ç”¨ Gemini API åˆ†ææå–æ ‡ç­¾
        analysis_result = analyze_content(content_for_analysis)

        # åˆå¹¶åŸå§‹æ ‡ç­¾å’Œ AI æ ‡ç­¾
        merged_tags = merge_tags(original_hashtags, analysis_result["tags"])

        # å­˜å…¥ Notionï¼Œä½†ä½¿ç”¨åŸå§‹å†…å®¹ä½œä¸ºæ‘˜è¦
        try:
            from services.notion_service import add_to_notion

            result = add_to_notion(
                content=content_for_storage,  # ä¿å­˜åŒ…å«æ ‡ç­¾çš„åŸå§‹å†…å®¹
                summary=cleaned_text if cleaned_text.strip() else content_for_storage,  # æ‘˜è¦ä½¿ç”¨æ¸…æ´æ–‡æœ¬
                tags=merged_tags,  # ä½¿ç”¨åˆå¹¶åçš„æ ‡ç­¾
                url=url,
                created_at=created_at,
                file_upload_ids=file_upload_ids if file_upload_ids else None,
            )

            # æ„å»ºå›å¤æ¶ˆæ¯
            reply_parts = ["âœ… å·²ä¿å­˜åˆ° Notion"]
            if file_upload_ids:
                reply_parts.append(f"ğŸ“· å·²ä¸Šä¼  {len(file_upload_ids)} å¼ å›¾ç‰‡")
            reply_parts.append(f"ğŸ“„ {result['title']}")
            reply_parts.append(f"ğŸ”— {result['url']}")

            update.message.reply_text(
                "\n".join(reply_parts),
                parse_mode=None
            )
        except Exception as e:
            logger.error(f"æ·»åŠ åˆ° Notion æ—¶å‡ºé”™ï¼š{e}")
            update.message.reply_text(
                f"âš ï¸ ä¿å­˜åˆ° Notion æ—¶å‡ºé”™ï¼š{str(e)}",
                parse_mode=None,  # ç¦ç”¨ Markdown è§£æ
            )
        return

    # é•¿å†…å®¹å¤„ç†ï¼šé€šçŸ¥ç”¨æˆ·æ­£åœ¨å¤„ç†
    processing_msg = (
        "æ­£åœ¨å¤„ç†è¾ƒé•¿æ¶ˆæ¯ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´..."
        if not contains_photo
        else "æ­£åœ¨å¤„ç†å›¾ç‰‡æ¶ˆæ¯ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´..."
    )
    update.message.reply_text(processing_msg, parse_mode=None)  # ç¦ç”¨ Markdown è§£æ

    # å¦‚æœæœ‰å›¾ç‰‡ï¼Œå…ˆä¸Šä¼ å›¾ç‰‡
    file_upload_ids = []
    if contains_photo:
        file_upload_ids = download_and_upload_photos(message, context)

    # ä½¿ç”¨ Gemini API å®Œæ•´åˆ†æå†…å®¹ï¼ˆä½¿ç”¨æ¸…æ´æ–‡æœ¬ï¼‰
    analysis_result = analyze_content(content_for_analysis)

    # åˆå¹¶åŸå§‹æ ‡ç­¾å’Œ AI æ ‡ç­¾
    merged_tags = merge_tags(original_hashtags, analysis_result["tags"])

    # å­˜å…¥ Notion
    try:
        from services.notion_service import add_to_notion

        result = add_to_notion(
            content=content_for_storage,  # ä¿å­˜åŒ…å«æ ‡ç­¾çš„åŸå§‹å†…å®¹
            summary=analysis_result["summary"],
            tags=merged_tags,  # ä½¿ç”¨åˆå¹¶åçš„æ ‡ç­¾
            url=url,
            created_at=created_at,
            file_upload_ids=file_upload_ids if file_upload_ids else None,
        )

        # æ„å»ºå›å¤æ¶ˆæ¯
        reply_parts = ["âœ… å·²ä¿å­˜åˆ° Notion"]
        if file_upload_ids:
            reply_parts.append(f"ğŸ“· å·²ä¸Šä¼  {len(file_upload_ids)} å¼ å›¾ç‰‡")
        reply_parts.append(f"ğŸ“„ {result['title']}")
        reply_parts.append(f"ğŸ”— {result['url']}")

        update.message.reply_text(
            "\n".join(reply_parts),
            parse_mode=None
        )
    except Exception as e:
        logger.error(f"æ·»åŠ åˆ° Notion æ—¶å‡ºé”™ï¼š{e}")
        update.message.reply_text(
            f"âš ï¸ ä¿å­˜åˆ° Notion æ—¶å‡ºé”™ï¼š{str(e)}",
            parse_mode=None,  # ç¦ç”¨ Markdown è§£æ
        )


def process_document(update: Update, context: CallbackContext) -> None:
    """å¤„ç†æ–‡æ¡£æ–‡ä»¶ï¼Œç‰¹åˆ«æ˜¯ PDF"""
    if update.effective_user.id not in ALLOWED_USER_IDS:
        return

    message = update.message

    # æ£€æŸ¥æ˜¯å¦æ˜¯ PDF æ–‡ä»¶
    if message.document.file_name.lower().endswith(".pdf"):
        handle_pdf_document(update, context)
    else:
        # å¯¹äºé PDF æ–‡ä»¶ï¼Œä½¿ç”¨å¸¸è§„å¤„ç†
        process_message(update, context)
